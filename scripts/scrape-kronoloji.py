#!/usr/bin/env python3
"""
HafÄ±za Cetveli - Wikipedia Kronoloji KazÄ±yÄ±cÄ±
https://tr.wikipedia.org/wiki/TÃ¼rk_KurtuluÅŸ_SavaÅŸÄ±_kronolojisi sayfasÄ±ndaki
verileri okur ve 'events/data/' klasÃ¶rÃ¼ne .md dosyalarÄ± olarak kaydeder.
"""

import os
import re
import requests
from bs4 import BeautifulSoup
from pathlib import Path

# --- AYARLAR ---
TARGET_URL = "https://tr.wikipedia.org/wiki/TÃ¼rk_KurtuluÅŸ_SavaÅŸÄ±_kronolojisi"
OUTPUT_DIR = "events/data"
EVENT_CATEGORY = "tarih" # TÃ¼m olaylar iÃ§in varsayÄ±lan kategori
SOURCE_URL = "https://tr.wikipedia.org/wiki/TÃ¼rk_KurtuluÅŸ_SavaÅŸÄ±_kronolojisi"
# ---------------

# TÃ¼rkÃ§e ay isimlerini sayÄ±sal formata Ã§evirmek iÃ§in harita
MONTH_MAP = {
    "Ocak": "01", "Åubat": "02", "Mart": "03", "Nisan": "04",
    "MayÄ±s": "05", "Haziran": "06", "Temmuz": "07", "AÄŸustos": "08",
    "EylÃ¼l": "09", "Ekim": "10", "KasÄ±m": "11", "AralÄ±k": "12"
}

def slugify(text):
    """
    Verilen metni (Ã¶rn: "Ay'a Ä°lk Ä°niÅŸ")
    dosya adÄ± iÃ§in gÃ¼venli bir formata (Ã¶rn: "aya-ilk-inis") dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    """
    text = text.lower()
    # TÃ¼rkÃ§e karakterleri dÃ¶nÃ¼ÅŸtÃ¼r
    text = text.replace('ÄŸ', 'g').replace('Ã¼', 'u').replace('ÅŸ', 's').replace('Ä±', 'i').replace('Ã¶', 'o').replace('Ã§', 'c')
    # Kalan tÃ¼m geÃ§ersiz karakterleri '-' ile deÄŸiÅŸtir
    text = re.sub(r'[^a-z0-9\s-]', '', text)
    # BoÅŸluklarÄ± '-' ile deÄŸiÅŸtir
    text = re.sub(r'[\s-]+', '-', text)
    return text.strip('-')

def format_date(day_month_str, year_str):
    """
    "30 Ekim" ve "1918" gibi iki metni "1918-10-30" formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    """
    try:
        parts = day_month_str.split()
        if len(parts) < 2:
             return None 
             
        day = parts[0]
        month_name = parts[1]
        
        # "1-2 AralÄ±k" gibi aralÄ±klarÄ± iÅŸle
        day = day.split('-')[0]
        if not day.isdigit():
            return None

        month = MONTH_MAP.get(month_name)
        if not month:
            return None
            
        day = day.zfill(2) # 01, 02...
        return f"{year_str}-{month}-{day}"
    except Exception as e:
        # print(f"    âš ï¸  Tarih formatÄ± hatasÄ±: {e} ({day_month_str})")
        return None

def create_markdown_file(date, title, description):
    """
    Verilen bilgilere gÃ¶re events/data/ klasÃ¶rÃ¼ne bir .md dosyasÄ± yazar.
    """
    slug = slugify(title)
    if not slug:
        print(f"    âš ï¸  BaÅŸlÄ±k {title} slug'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lemedi, atlanÄ±yor.")
        return False

    filename = f"{date}-{slug}.md"
    filepath = Path(OUTPUT_DIR) / filename
    
    # YAML front matter ve iÃ§eriÄŸi hazÄ±rla
    content = f"""---
title: "{title}"
date: {date}
category: {EVENT_CATEGORY}
---

{description.strip()}

## Kaynaklar

{SOURCE_URL}
"""
    
    try:
        if filepath.exists():
            print(f"    â„¹ï¸  Dosya zaten var, atlanÄ±yor: {filename}")
            return False

        filepath.write_text(content, encoding='utf-8')
        print(f"    âœ…  OluÅŸturuldu: {filename}")
        return True
    except Exception as e:
        print(f"    âŒ  HATA: {filename} dosyasÄ± yazÄ±lamadÄ±: {e}")
        return False

def scrape_chronology():
    """
    Ana kazÄ±ma (scraping) fonksiyonu.
    """
    print(f"ğŸ“œ Wikipedia sayfasÄ±ndan veri Ã§ekiliyor: {TARGET_URL}")
    
    try:
        headers = {'User-Agent': 'HafizaCetveliScraper/1.0 (https://github.com/sergenaras/hafiza)'}
        response = requests.get(TARGET_URL, headers=headers)
        response.raise_for_status() 
    except requests.RequestException as e:
        print(f"âŒ HATA: Wikipedia sayfasÄ±na eriÅŸilemedi: {e}")
        return

    soup = BeautifulSoup(response.text, 'html.parser')
    
    content_div = soup.find('div', {'class': 'mw-parser-output'})
    if not content_div:
        print("âŒ HATA: Sayfa yapÄ±sÄ± deÄŸiÅŸmiÅŸ, 'mw-parser-output' alanÄ± bulunamadÄ±.")
        return

    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    
    event_count = 0
    
    # DÃœZELTME: 'span' yerine doÄŸrudan 'h2' etiketlerini bul
    headlines = content_div.find_all('h2')
    
    current_year = ""

    for headline in headlines:
        # h2 etiketinin 'id' Ã¶zelliÄŸini al (span'den deÄŸil)
        year_id = headline.get('id')
        
        if not year_id:
            continue # ID'si olmayan h2'leri (Ã¶rn: "KaynakÃ§a") atla
        
        # ID'nin 4 haneli bir yÄ±l olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        if re.fullmatch(r'\d{4}', year_id):
            current_year = year_id
            print(f"\nğŸ—“ï¸  YÄ±l iÅŸleniyor: {current_year}")
            
            # Bu 'h2' etiketini iÃ§eren 'div.mw-heading'i bul
            parent_div = headline.find_parent('div', {'class': 'mw-heading'})
            if not parent_div:
                parent_div = headline # Bazen div olmayabilir, h2'yi temel al

            # O baÅŸlÄ±ktan sonraki 'table' etiketini bul
            # HATA DÃœZELTMESÄ°: {'class': 'wikitable'} kaldÄ±rÄ±ldÄ±
            table = parent_div.find_next_sibling('table')
            
            if not table:
                print(f"    â„¹ï¸  {current_year} yÄ±lÄ± iÃ§in tablo bulunamadÄ±, atlanÄ±yor.")
                continue
                
            # EÄŸer bu bir 'navbox' ise atla (sayfa sonundaki ÅŸablonlar)
            if 'navbox' in (table.get('class') or []):
                continue

            # Tabloyu iÅŸle
            for row in table.find_all('tr'):
                cells = row.find_all('td')
                
                if len(cells) < 2:
                    continue # Header (th) veya geÃ§ersiz satÄ±r
                
                day_month_str = cells[0].get_text(strip=True)
                description = cells[1].get_text(strip=True)
                
                full_date = format_date(day_month_str, current_year)
                if not full_date:
                    continue # Tarih formatÄ± anlaÅŸÄ±lamadÄ±
                
                if not description:
                    description = "AÃ§Ä±klama bulunamadÄ±."
                
                # BaÅŸlÄ±ÄŸÄ± oluÅŸtur
                title = (description.split('.')[0]).strip()
                if len(title) > 60: 
                    title = title[:60].strip() + "..."
                elif not title:
                     title = f"{current_year} OlayÄ±"

                if create_markdown_file(full_date, title, description):
                    event_count += 1

    print(f"\nâœ¨ Ä°ÅŸlem tamamlandÄ±. Toplam {event_count} olay dosyasÄ± oluÅŸturuldu.")

if __name__ == "__main__":
    scrape_chronology()